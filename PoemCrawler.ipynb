{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e8ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import csv\n",
    "import fake_useragent\n",
    "import threading\n",
    " \n",
    "ua = fake_useragent.UserAgent()  # ua伪装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8bbb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代理池\n",
    "import requests\n",
    "\n",
    "PROXY_POOL_URL = 'http://localhost:5555/random'\n",
    "proxies = \"\"\n",
    "\n",
    "\n",
    "def get_proxy():\n",
    "    try:\n",
    "        response = requests.get(PROXY_POOL_URL)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "    except ConnectionError:\n",
    "        return None\n",
    "    \n",
    "# print(get_proxy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d9a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"https://www.shicimingju.com/chaxun/zuozhe/\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                         'Chrome/97.0.4692.71 Safari/537.36 Edg/97.0.1072.62'}\n",
    "i = 1  # 诗人\n",
    "j = 1  # 诗页\n",
    "count = 0  # 诗人诗歌数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f38430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义需要的列表\n",
    "poets_list = []\n",
    "titles_list = []\n",
    "dynasty_list = []\n",
    "types_list = []\n",
    "introductions_list = []\n",
    "content_list = []\n",
    "count_list = []\n",
    "\n",
    "types_set_list = []  # 去重\n",
    "dynasty_set_list = []  # 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7564eb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立csv节点文件\n",
    "f_poets = open('./poets.csv', 'w', newline=\"\")\n",
    "f_dynasty = open('./dynasty.csv', 'w', newline=\"\")\n",
    "f_poems = open('./poems.csv', 'w', newline=\"\")\n",
    "f_types = open('./types.csv', 'w', newline=\"\")\n",
    "\n",
    "writer_poets = csv.writer(f_poets)\n",
    "writer_poets.writerow(['index:name', 'introduction', ':LABEL'])\n",
    "\n",
    "writer_dynasty = csv.writer(f_dynasty)\n",
    "writer_dynasty.writerow(['index:dynasty', ':LABEL'])\n",
    "\n",
    "writer_poems = csv.writer(f_poems)\n",
    "writer_poems.writerow(['index:title', 'content', ':LABEL'])\n",
    "\n",
    "writer_types = csv.writer(f_types)\n",
    "writer_types.writerow(['index:type', ':LABEL'])\n",
    "\n",
    "\n",
    "\n",
    "# 建立csv关系文件\n",
    "f_poets_dynasty = open('./poets_dynasty.csv', 'w', newline=\"\")\n",
    "f_poems_dynasty = open('./poems_dynasty.csv', 'w', newline=\"\")\n",
    "f_poets_poems = open('./poets_poems.csv', 'w', newline=\"\")\n",
    "f_poems_types = open('./poems_types.csv', 'w', newline=\"\")\n",
    "\n",
    "writer_poets_dynasty = csv.writer(f_poets_dynasty)\n",
    "writer_poets_dynasty.writerow([':START_name', ':END_dynasty', 'relation', ':TYPE'])\n",
    "\n",
    "writer_poems_dynasty = csv.writer(f_poems_dynasty)\n",
    "writer_poems_dynasty.writerow([':START_title', ':END_dynasty', 'relation', ':TYPE'])\n",
    "\n",
    "writer_poets_poems = csv.writer(f_poets_poems)\n",
    "writer_poets_poems.writerow([':START_name', ':END_title', 'relation', ':TYPE'])\n",
    "\n",
    "writer_poems_types = csv.writer(f_poems_types)\n",
    "writer_poems_types.writerow([':START_title', ':END_type', 'relation', ':TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623b95c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.31.2.38:8999\n",
      "157.230.34.219:3128\n"
     ]
    }
   ],
   "source": [
    "# 多线程技术\n",
    "import threading\n",
    "import time\n",
    " \n",
    "# 这个函数名可随便定义\n",
    "def get_ip():\n",
    "    while True:\n",
    "        if get_proxy() is not None:\n",
    "            proxies = get_proxy()\n",
    "            time.sleep(1)\n",
    "            print(proxies)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "t1 = threading.Thread(target=get_ip)\n",
    "t1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04aa78d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.241.132.30:80\n",
      "苏轼的《西江月　送别》爬取成功！\n",
      "183.221.242.107:8443\n",
      "苏轼的《江神子/江城子》爬取成功！\n",
      "110.34.3.229:3128\n",
      "苏轼的《江神子/江城子》爬取成功！\n",
      "173.212.200.30:3128\n",
      "苏轼的《江神子/江城子》爬取成功！\n",
      "110.34.3.229:3128\n",
      "苏轼的《江神子/江城子》爬取成功！\n",
      "122.155.165.191:3128\n",
      "苏轼的《江神子/江城子》爬取成功！\n",
      "110.34.3.229:3128\n",
      "苏轼的《古意》爬取成功！\n",
      "苏轼的《浣溪沙 咏橘》爬取成功！\n",
      "105.112.191.250:3128\n",
      "苏轼的《桃源忆故人·华胥梦断人何处》爬取成功！\n",
      "122.9.21.228:8000\n",
      "苏轼的《天仙子·走马探花花发未》爬取成功！\n",
      "182.241.132.30:80\n",
      "苏轼的《西江月　平山堂》爬取成功！\n",
      "苏轼的《竹》爬取成功！\n",
      "66.94.108.138:3128\n",
      "苏轼的《阮郎归 初夏》爬取成功！\n",
      "110.34.3.229:3128\n",
      "\n",
      "'gbk' codec can't encode character '\\u2022' in position 4: illegal multibyte sequence\n",
      "66.94.108.138:3128\n",
      "118.31.2.38:8999\n",
      "122.9.21.228:8000\n",
      "105.112.191.250:3128\n",
      "182.241.132.30:80\n",
      "182.241.132.30:80\n",
      "183.221.242.107:8443\n"
     ]
    }
   ],
   "source": [
    "# 主爬取&写入函数\n",
    "def main():\n",
    "    global i\n",
    "    global j\n",
    "    global count\n",
    "    while 1:\n",
    "\n",
    "        try:  # 诗人已经到达尽头，可以退出爬取了\n",
    "\n",
    "            # 网页构建\n",
    "            web = website + str(i) + \"_\" + str(j) + \".html\"\n",
    "\n",
    "            # 古诗列表模式\n",
    "            try:\n",
    "                response = requests.get(url=web, headers={'User-Agent': ua.random}, proxies={\"http\":proxies})\n",
    "            except:\n",
    "                response = requests.get(url=web, headers={'User-Agent': ua.random})\n",
    "            page_text = response.content  # content防止中文乱码问题\n",
    "            tree = etree.HTML(page_text)\n",
    "\n",
    "            poet = tree.xpath('//*[@id=\"main_right\"]/div[1]/div[2]/div[1]/h4/a/text()')[0]  # 诗人\n",
    "            dynasty = tree.xpath('//*[@id=\"main_right\"]/div[1]/div[3]/div[1]/div[2]/a/text()')[0]  # 朝代\n",
    "\n",
    "            try:  # 诗人介绍有可能不存在\n",
    "                # 诗人介绍\n",
    "                poet_intr = tree.xpath('//*[@id=\"main_right\"]/div[1]/div[2]/div[1]/div/text()')\n",
    "                intr_max = \"\"\n",
    "                for intr in poet_intr:\n",
    "                    intr_max += intr\n",
    "                intr_max = intr_max.strip()\n",
    "            except:\n",
    "                intr_max = \"\"\n",
    "\n",
    "            try:\n",
    "                # 诗歌总页数的列表\n",
    "                poet_all = tree.xpath('//*[@id=\"list_nav_all\"]/a')\n",
    "                poet_num = len(poet_all)\n",
    "            except:\n",
    "                poet_num = 1\n",
    "\n",
    "            # 诗文列表\n",
    "            poet_list = tree.xpath('//*[@id=\"main_left\"]/div[1]/div')\n",
    "\n",
    "            for poet_pre in poet_list[1::2]:  # 跳一个取一个\n",
    "                title = poet_pre.xpath('./div[2]/h3/a/text()')[0]  # 标题\n",
    "\n",
    "                # 古诗详情页\n",
    "                poet_url = \"https://www.shicimingju.com\" + poet_pre.xpath('./div[2]/h3/a/@href')[0]\n",
    "                # 进入具体古诗页面\n",
    "                try:\n",
    "                    response = requests.get(url=poet_url, headers={'User-Agent': ua.random}, proxies={\"http\":proxies})\n",
    "                except:\n",
    "                    response = requests.get(url=poet_url, headers={'User-Agent': ua.random})\n",
    "                    \n",
    "                page_text = response.content  # content防止中文乱码问题\n",
    "                tree = etree.HTML(page_text)\n",
    "\n",
    "                # 诗歌内容\n",
    "                content = tree.xpath('//*[@id=\"zs_content\"]/text()')\n",
    "                content_max = \"\"\n",
    "                for con in content:\n",
    "                    content_max += con\n",
    "                content_max = content_max.strip()\n",
    "\n",
    "                # 诗歌标签\n",
    "                try:\n",
    "                    labels = tree.xpath('//*[@id=\"item_div\"]/div[5]/a/text()')\n",
    "                except:\n",
    "                    labels = [\"暂无\"]\n",
    "\n",
    "                # 循环赋值\n",
    "                poets_list.append(poet)\n",
    "                titles_list.append(title)\n",
    "                dynasty_list.append(dynasty)\n",
    "                types_list.append(labels)\n",
    "                introductions_list.append(intr_max)\n",
    "                content_list.append(content_max)\n",
    "                count += 1  # 计数\n",
    "\n",
    "\n",
    "                # 写入文件\n",
    "                for label in labels:  # 去重类型\n",
    "                    if label not in types_set_list:\n",
    "                        types_set_list.append(label)\n",
    "                        writer_types.writerow([label, '类型'])\n",
    "                    writer_poems_types.writerow([title, label, 'belongto', '属于'])\n",
    "\n",
    "                # 去重朝代\n",
    "                if dynasty not in dynasty_set_list:\n",
    "                    dynasty_set_list.append(dynasty)\n",
    "                    writer_dynasty.writerow([dynasty, '朝代'])\n",
    "\n",
    "                if j == 1:  # 诗人变更\n",
    "                    writer_poets.writerow([poet, intr_max, \"诗人\"])\n",
    "                    writer_poets_dynasty.writerow([poet, dynasty, 'livein', '生活于'])\n",
    "\n",
    "                writer_poems.writerow([title, content_max, '诗词'])\n",
    "                writer_poems_dynasty.writerow([title, dynasty, 'writenin', '创作于'])\n",
    "                writer_poets_poems.writerow([poet, title, 'write', '写作'])\n",
    "\n",
    "                print(\"{0}的{1}爬取成功！\".format(poet, title))\n",
    "\n",
    "            # 判断条件\n",
    "            if j < poet_num:\n",
    "                j += 1  # 循环完成一页\n",
    "                print(\"-----------------------------第{0}页爬取完毕--------------------------------\".format(j - 1))\n",
    "            else:  # 此诗人循环完毕，进行下一个诗人爬取\n",
    "                i += 1  # 诗人切换\n",
    "                j = 1  # 页数归零\n",
    "                print(\"============================================================================\")\n",
    "                print(\"{0}爬取完毕，共获得{1}首诗歌！！\".format(poet, count))\n",
    "                print(\"============================================================================\")\n",
    "                count_list.append(\"count\")\n",
    "                count = 0  # 计数清零\n",
    "\n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "            \n",
    "t2 = threading.Thread(target=main)  # , args=(\"thread 2\",))\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a31024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb2da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 古诗详情页\n",
    "poet_url = \"https://www.shicimingju.com/chaxun/list/109357.html\"\n",
    "# 进入具体古诗页面\n",
    "response = requests.get(url=poet_url, headers={'User-Agent': ua.random}, proxies={\"http\":get_proxy()})\n",
    "page_text = response.content  # content防止中文乱码问题\n",
    "tree = etree.HTML(page_text)\n",
    "\n",
    "# 诗歌内容\n",
    "content = tree.xpath('//*[@id=\"zs_content\"]/text()')\n",
    "content_max = \"\"\n",
    "for con in content:\n",
    "    content_max += con\n",
    "content_max = content_max.replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "# content_max = content_max.strip()\n",
    "print(content_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a1821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26283fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03eb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a42f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792de1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "\n",
    "    try:  # 诗人已经到达尽头，可以退出爬取了\n",
    "\n",
    "        # 网页构建\n",
    "        web = website + str(i) + \"_\" + str(j) + \".html\"\n",
    "\n",
    "        # 古诗列表模式\n",
    "        if get_proxy() is not None:\n",
    "            response = requests.get(url=web, headers={'User-Agent': ua.random}, proxies={\"http\":get_proxy()})\n",
    "        else:\n",
    "            response = requests.get(url=web, headers={'User-Agent': ua.random})\n",
    "        page_text = response.content  # content防止中文乱码问题\n",
    "        tree = etree.HTML(page_text)\n",
    "\n",
    "        poet = tree.xpath('//*[@id=\"main_right\"]/div[1]/div[2]/div[1]/h4/a/text()')[0]  # 诗人\n",
    "        dynasty = tree.xpath('//*[@id=\"main_right\"]/div[1]/div[3]/div[1]/div[2]/a/text()')[0]  # 朝代\n",
    "\n",
    "        try:  # 诗人介绍有可能不存在\n",
    "            # 诗人介绍\n",
    "            poet_intr = tree.xpath('//*[@id=\"main_right\"]/div[1]/div[2]/div[1]/div/text()')\n",
    "            intr_max = \"\"\n",
    "            for intr in poet_intr:\n",
    "                intr_max += intr\n",
    "            intr_max = intr_max.strip()\n",
    "        except:\n",
    "            intr_max = \"\"\n",
    "\n",
    "        try:\n",
    "            # 诗歌总页数的列表\n",
    "            poet_all = tree.xpath('//*[@id=\"list_nav_all\"]/a')\n",
    "            poet_num = len(poet_all)\n",
    "        except:\n",
    "            poet_num = 1\n",
    "\n",
    "        # 诗文列表\n",
    "        poet_list = tree.xpath('//*[@id=\"main_left\"]/div[1]/div')\n",
    "\n",
    "        for poet_pre in poet_list[1::2]:  # 跳一个取一个\n",
    "            title = poet_pre.xpath('./div[2]/h3/a/text()')[0]  # 标题\n",
    "\n",
    "            # 古诗详情页\n",
    "            poet_url = \"https://www.shicimingju.com\" + poet_pre.xpath('./div[2]/h3/a/@href')[0]\n",
    "            # 进入具体古诗页面\n",
    "            if get_proxy() is not None:\n",
    "                response = requests.get(url=poet_url, headers={'User-Agent': ua.random}, proxies={\"http\":get_proxy()})\n",
    "            else:\n",
    "                response = requests.get(url=poet_url, headers={'User-Agent': ua.random})\n",
    "            page_text = response.content  # content防止中文乱码问题\n",
    "            tree = etree.HTML(page_text)\n",
    "\n",
    "            # 诗歌内容\n",
    "            content = tree.xpath('//*[@id=\"zs_content\"]/text()')\n",
    "            content_max = \"\"\n",
    "            for con in content:\n",
    "                content_max += con\n",
    "            content_max = content_max.strip()\n",
    "\n",
    "            # 诗歌标签\n",
    "            try:\n",
    "                label = tree.xpath('//*[@id=\"item_div\"]/div[5]/a/text()')\n",
    "            except:\n",
    "                label = [\"暂无\"]\n",
    "\n",
    "            # 循环赋值\n",
    "            poets_list.append(poet)\n",
    "            titles_list.append(title)\n",
    "            dynasty_list.append(dynasty)\n",
    "            types_list.append(label)\n",
    "            introductions_list.append(intr_max)\n",
    "            content_list.append(content_max)\n",
    "            count += 1  # 计数\n",
    "            print(\"{0}的{1}爬取成功！\".format(poet, title))\n",
    "\n",
    "        # 判断条件\n",
    "        if j < poet_num:\n",
    "            j += 1  # 循环完成一页\n",
    "            print(\"-----------------------------第{0}页爬取完毕--------------------------------\".format(j - 1))\n",
    "        else:  # 此诗人循环完毕，进行下一个诗人爬取\n",
    "            i += 1  # 诗人切换\n",
    "            j = 1  # 页数归零\n",
    "            print(\"============================================================================\")\n",
    "            print(\"{0}爬取完毕，共获得{1}首诗歌！！\".format(poet, count))\n",
    "            print(\"============================================================================\")\n",
    "            count_list.append(\"count\")\n",
    "            count = 0  # 计数清零\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datapro_py39",
   "language": "python",
   "name": "datapro_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
